# R-JEPA Windows Service Setup

Guide pour faire tourner R-JEPA en tant que service Windows (d√©marrage automatique au boot).

## üéØ Qu'est-ce qu'un service Windows ?

Un service Windows permet de faire tourner une application en arri√®re-plan de fa√ßon permanente, m√™me sans √™tre connect√©. Les avantages :

- ‚úÖ **D√©marrage automatique** au boot de Windows
- ‚úÖ **Red√©marrage automatique** en cas de crash
- ‚úÖ **Ex√©cution en arri√®re-plan** (pas besoin de terminal ouvert)
- ‚úÖ **Logging centralis√©** dans des fichiers
- ‚úÖ **Gestion via Services Windows** (services.msc)

## üì¶ Services disponibles

### 1. **Student LLM Server** (`RJEPA-StudentLLM`)
Serveur FastAPI qui expose Qwen3-8B sur GPU pour :
- G√©n√©ration de CoT structur√©s
- Extraction de latents

**Utilisation** : Permet √† d'autres composants (UI, pipeline) d'appeler le LLM via HTTP

### 2. **Latent Extraction** (`RJEPA-LatentExtraction`)
Pipeline d'extraction continue qui surveille les nouveaux datasets et g√©n√®re automatiquement les latents.

**Utilisation** : Traitement batch automatique des nouveaux probl√®mes

### 3. **Continuous Training** (`RJEPA-ContinuousTraining`)
Boucle d'entra√Ænement continue qui re-entra√Æne R-JEPA chaque nuit avec les nouvelles donn√©es.

**Utilisation** : Apprentissage continu du syst√®me (am√©lioration progressive)

## üöÄ Installation

### Pr√©requis
- ‚úÖ Windows 11 (ou 10)
- ‚úÖ Droits administrateur
- ‚úÖ Python venv configur√© (`.venv`)
- ‚úÖ GPU NVIDIA avec CUDA 12.1+

### √âtape 1 : Installer NSSM

Le script PowerShell t√©l√©charge et installe automatiquement **NSSM (Non-Sucking Service Manager)**, un outil qui transforme n'importe quel ex√©cutable en service Windows.

### √âtape 2 : Installer un service

Ouvrir PowerShell **en tant qu'administrateur** :

```powershell
# Se placer dans le projet
cd C:\Users\teleadmin\world-txt-model

# Installer le service Student LLM
.\scripts\setup_windows_service.ps1 -Service student-llm -Install

# Ou installer tous les services d'un coup
.\scripts\setup_windows_service.ps1 -Service all -Install
```

### √âtape 3 : D√©marrer le service

```powershell
# D√©marrer Student LLM
.\scripts\setup_windows_service.ps1 -Service student-llm -Start

# V√©rifier le statut
.\scripts\setup_windows_service.ps1 -Service student-llm -Status
```

Le service va :
1. Charger le mod√®le Qwen3-8B sur cuda:0
2. D√©marrer le serveur FastAPI sur port 8000
3. Logger dans `logs/student-llm/service.log`

### √âtape 4 : V√©rifier que √ßa marche

```bash
# Test HTTP
curl http://localhost:8000/health

# Devrait retourner:
# {"status":"ok","model":"Qwen/Qwen3-8B","hidden_size":4096,...}
```

## üìä Gestion des services

### Voir le statut

```powershell
.\scripts\setup_windows_service.ps1 -Service student-llm -Status
```

### Arr√™ter un service

```powershell
.\scripts\setup_windows_service.ps1 -Service student-llm -Stop
```

### Red√©marrer un service

```powershell
# Arr√™ter puis red√©marrer
.\scripts\setup_windows_service.ps1 -Service student-llm -Stop
.\scripts\setup_windows_service.ps1 -Service student-llm -Start
```

### D√©sinstaller un service

```powershell
.\scripts\setup_windows_service.ps1 -Service student-llm -Uninstall
```

## üìù Logs

Les logs de chaque service sont dans :

```
logs/
‚îú‚îÄ student-llm/
‚îÇ   ‚îî‚îÄ service.log          ‚Üê Logs du serveur LLM
‚îú‚îÄ latent-extraction/
‚îÇ   ‚îî‚îÄ service.log          ‚Üê Logs de l'extraction
‚îî‚îÄ training/
    ‚îî‚îÄ service.log          ‚Üê Logs du training continu
```

Pour voir les logs en temps r√©el :

```powershell
# PowerShell
Get-Content -Path ".\logs\student-llm\service.log" -Wait

# Ou Git Bash
tail -f logs/student-llm/service.log
```

## üõ†Ô∏è Configuration avanc√©e

### Changer le port du Student LLM

Par d√©faut, le serveur √©coute sur port 8000. Pour changer :

1. Ouvrir `scripts\setup_windows_service.ps1`
2. Modifier la ligne `Args` pour `student-llm` :
   ```powershell
   Args = "--port 8080 --model Qwen/Qwen3-8B --device cuda:0"
   ```
3. R√©installer le service :
   ```powershell
   .\scripts\setup_windows_service.ps1 -Service student-llm -Uninstall
   .\scripts\setup_windows_service.ps1 -Service student-llm -Install
   .\scripts\setup_windows_service.ps1 -Service student-llm -Start
   ```

### Utiliser un autre mod√®le

Pour utiliser Qwen3-32B au lieu de Qwen3-8B :

```powershell
Args = "--port 8000 --model Qwen/Qwen3-32B --device cuda:0 --quantization awq-4bit"
```

### Variables d'environnement

Le service d√©finit automatiquement :
- `CUDA_VISIBLE_DEVICES=0` (utilise seulement GPU 0)

Pour ajouter d'autres variables :

```powershell
& $NSSMPath set RJEPA-StudentLLM AppEnvironmentExtra "CUDA_VISIBLE_DEVICES=0`nTRANSFORMERS_CACHE=C:\cache"
```

## üîç D√©pannage

### Le service ne d√©marre pas

1. **V√©rifier les logs** :
   ```powershell
   Get-Content .\logs\student-llm\service.log -Tail 50
   ```

2. **V√©rifier que Python venv est correct** :
   ```powershell
   .\.venv\Scripts\python.exe --version
   # Devrait afficher: Python 3.11.9
   ```

3. **Tester manuellement** :
   ```bash
   cd /c/Users/teleadmin/world-txt-model
   source .venv/Scripts/activate
   python rjepa/llm/server.py
   ```

4. **V√©rifier CUDA** :
   ```bash
   nvidia-smi
   # Devrait montrer le GPU
   ```

### Le service plante au bout de quelques heures

Probl√®me courant : **Out of Memory (OOM)**

Solutions :
1. **Ajouter un swap GPU** (pas recommand√©, lent)
2. **R√©duire batch size** dans les configs
3. **Utiliser quantization** (AWQ 4-bit)
4. **Red√©marrage automatique** :
   ```powershell
   & $NSSMPath set RJEPA-StudentLLM AppExit Default Restart
   & $NSSMPath set RJEPA-StudentLLM AppRestartDelay 5000
   ```

### Le mod√®le charge sur CPU au lieu de GPU

V√©rifier dans les logs :
```
Device: cuda:0 ‚úÖ  (bon)
Device: cpu ‚ùå     (mauvais)
```

Si c'est CPU :
1. **V√©rifier CUDA** : `nvidia-smi`
2. **V√©rifier PyTorch** :
   ```bash
   .venv/Scripts/python.exe -c "import torch; print(torch.cuda.is_available())"
   # Devrait afficher: True
   ```
3. **R√©installer PyTorch avec CUDA** si False :
   ```bash
   pip uninstall torch
   pip install torch --index-url https://download.pytorch.org/whl/cu121
   ```

## üéõÔ∏è Services Windows (GUI)

Vous pouvez aussi g√©rer les services via l'interface Windows :

1. **Ouvrir Services** : `Win+R` ‚Üí `services.msc`
2. **Chercher** `RJEPA-StudentLLM`
3. **Clic droit** ‚Üí D√©marrer / Arr√™ter / Red√©marrer

Propri√©t√©s utiles :
- **D√©marrage automatique** : Le service d√©marre au boot Windows
- **Red√©marrage automatique** : Red√©marre si crash
- **Connexion** : Compte utilisateur (par d√©faut : Syst√®me Local)

## üìö R√©f√©rences

- **NSSM** : https://nssm.cc/
- **PowerShell** : Documentation Microsoft
- **FastAPI** : https://fastapi.tiangolo.com/

## ‚úÖ Checklist de production

Avant de laisser tourner en production :

- [ ] Service install√© et d√©marre au boot
- [ ] Logs v√©rifi√©s (pas d'erreurs)
- [ ] GPU utilis√© (pas CPU)
- [ ] Endpoint `/health` r√©pond
- [ ] Red√©marrage automatique configur√©
- [ ] Monitoring (optionnel : Prometheus + Grafana)
- [ ] Backup des checkpoints R-JEPA

## üöÄ Quick Start (TL;DR)

```powershell
# En administrateur
cd C:\Users\teleadmin\world-txt-model

# Installer + d√©marrer Student LLM
.\scripts\setup_windows_service.ps1 -Service student-llm -Install
.\scripts\setup_windows_service.ps1 -Service student-llm -Start

# V√©rifier
curl http://localhost:8000/health

# Voir logs
tail -f logs/student-llm/service.log
```

Voil√†! üéâ
