# Audit Complet : Batching & Optimisations R-JEPA

**Date** : 2025-11-18
**Objectif** : V√©rifier que le batching et les optimisations fonctionnent avec le service et la queue d'entra√Ænement.

---

## üìà R√âSULTATS TESTS DE VITESSE

### Test 1 : Sans Batching (S√©quentiel)
- **Vitesse** : 41 secondes/probl√®me ‚ùå
- **Extrapolation** : 244 heures (10 jours) pour 21,456 probl√®mes
- **Probl√®me** : BEAUCOUP TROP LENT

### Test 2 : Avec Batching (batch_size=8)
- **Vitesse** : 5.67 secondes/probl√®me ‚úÖ
- **Extrapolation** : 33.8 heures (~1.4 jours) pour 21,456 probl√®mes
- **Gain** : **7.2x plus rapide** üöÄ

### Test 3 : Avec Batching (batch_size=16)
- **Vitesse** : 18.48 secondes/probl√®me ‚ùå
- **Extrapolation** : 110.1 heures (~4.6 jours) pour 21,456 probl√®mes
- **Probl√®me** : 3.3x PLUS LENT que batch_size=8 (GPU memory swapping)

### Conclusion Tests
‚úÖ **batch_size=8 est OPTIMAL** pour RTX 4090 avec Qwen3-8B AWQ 4-bit
‚ùå Au-del√†, le GPU a du mal (memory swapping, overhead)

---

## üîç AUDIT ARCHITECTURE

### 1. **Script d'Extraction Optimis√©** (`scripts/extract_latents_optimized.py`)

**Status** : ‚úÖ OPTIMAL

```python
# Batching impl√©ment√© (ligne 173-178)
def generate_and_extract_batch(self, problems: List[Dict], ...):
    # G√©n√®re batch_size probl√®mes en parall√®le sur GPU
    ...
```

**Configuration** :
- `--batch-size 8` (RECOMMAND√â)
- `--limit N` pour tests
- `--resume` pour checkpoint/reprendre

**Performances** :
- batch_size=8 : 5.67s/probl√®me
- Full dataset : ~34h

---

### 2. **Pipeline Officiel** (`rjepa/pipeline/build_latents.py`)

**Status** : ‚ö†Ô∏è **BESOIN D'OPTIMISATION**

**Probl√®me Actuel** (ligne 96) :
```python
for cot_data in tqdm(cots_data):  # ‚ùå S√âQUENTIEL, pas de batching
    H = llm.extract_latents(...)
```

**Fix Appliqu√©** :
- Ajout param√®tre `batch_size=8` dans signature
- TODO : Impl√©menter logique de batching dans la boucle

**Recommandation** :
Pour l'instant, utiliser `scripts/extract_latents_optimized.py` pour extraction rapide.
Le pipeline officiel sera optimis√© dans une prochaine phase.

---

### 3. **Training Pipeline** (`rjepa/jepa/dataset.py` + `rjepa/pipeline/train_rjepa.py`)

**Status** : ‚úÖ **BATCHING OK**

**Architecture** :
```python
# dataset.py - Charge latents pr√©-extraits
class LatentDataset(Dataset):
    def __getitem__(self, idx):
        return latents[idx], domain_id

# train_rjepa.py - DataLoader PyTorch avec batching
train_loader = DataLoader(
    train_dataset,
    batch_size=config["training"]["batch_size"],  # ‚úÖ Configurable
    shuffle=True,
    num_workers=4,  # ‚úÖ Multi-threading
)
```

**Config YAML** (`configs/rjepa/train.yaml`) :
```yaml
training:
  batch_size: 32  # Optimal pour training R-JEPA
  num_workers: 4
```

**Verdict** : ‚úÖ **Aucun probl√®me**, PyTorch DataLoader g√®re le batching automatiquement.

---

### 4. **Service d'Inf√©rence** (`rjepa/jepa/service.py`)

**Status** : ‚úÖ **OK mais pas de batching c√¥t√© serveur**

**Architecture** :
```python
@app.post("/score")
def score(request: ScoreRequest):
    # Accepte 1 s√©quence √† la fois
    latents = torch.tensor(request.latents)  # [num_steps, hidden_dim]
    latents = latents.unsqueeze(0)  # ‚úÖ Ajoute batch dim [1, S, D]
    result = model.score(latents, ...)
    return result
```

**Justification** :
- API REST simple : 1 requ√™te = 1 s√©quence
- Batching c√¥t√© client possible si n√©cessaire (ex: UI backend)
- Pour inf√©rence temps r√©el, batching n'est pas critique

**Verdict** : ‚úÖ **Acceptable pour l'inf√©rence**

---

## üéØ RECOMMANDATIONS FINALES

### Pour Extraction de Latents (21,456 probl√®mes) :

1. **Utiliser `extract_latents_optimized.py`** :
   ```bash
   python scripts/extract_latents_optimized.py \
     --batch-size 8 \
     --checkpoint-every 10 \
     --resume  # Si besoin de reprendre
   ```

2. **Temps estim√©** : ~34 heures (~1.4 jours)

3. **Optimisation future** :
   - Int√©grer le batching dans `rjepa/pipeline/build_latents.py`
   - Permettre de r√©utiliser le script optimis√© via Prefect

### Pour Training R-JEPA :

‚úÖ **Aucune modification requise**
- DataLoader PyTorch g√®re le batching
- Config YAML contr√¥le batch_size

### Pour Service d'Inf√©rence :

‚úÖ **Aucune modification requise**
- API simple (1 s√©quence √† la fois)
- Batching c√¥t√© client si besoin

---

## üêõ BUGS IDENTIFI√âS & FIXES

### 1. Double Forward Pass (adapter.py)

**Probl√®me** : IMPOSSIBLE √† √©viter avec HuggingFace `generate()`
- `model.generate()` ne retourne pas les hidden states
- Oblig√©s de faire un 2√®me forward pass pour extraction

**Status** : ‚ö†Ô∏è **Limitation HuggingFace, pas un bug**

**Impact** : Temps d'extraction x2, mais inevitable.
Le vrai gain vient du batching, pas de l'√©limination du double pass.

### 2. Scripts Multiples

**Fix** : ‚úÖ **Scripts obsol√®tes supprim√©s**
- Supprim√© : `test_latent_extraction.py`
- Supprim√© : `extract_latents_from_problems.py`
- Conserv√© : `extract_latents_optimized.py` (seul script valide)

---

## ‚úÖ CONCLUSION

| Composant | Status | Batching | Performance |
|-----------|--------|----------|-------------|
| Script optimis√© | ‚úÖ OK | batch_size=8 | 5.67s/probl√®me |
| Pipeline officiel | ‚ö†Ô∏è TODO | Aucun | ~41s/probl√®me |
| Training | ‚úÖ OK | PyTorch DataLoader | Config YAML |
| Service | ‚úÖ OK | Single sample API | Acceptable |

**Action Imm√©diate** :
Lancer extraction compl√®te avec script optimis√© (~34h).

**Action Future** :
Optimiser `build_latents.py` pour utiliser le batching.
