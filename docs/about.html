<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Understanding R-JEPA: A World Model for Text Reasoning - How it works, why it matters, and what problems it solves.">
    <title>About R-JEPA | Understanding World Models for Reasoning</title>
    <link rel="canonical" href="https://cognition4ai.com/about.html">
    <link rel="icon" type="image/svg+xml" href="data:image/svg+xml,<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 100 100'><text y='.9em' font-size='90'>üß†</text></svg>">
    <style>
        :root {
            --primary: #6366f1;
            --primary-dark: #4f46e5;
            --secondary: #0ea5e9;
            --bg-dark: #0f172a;
            --bg-card: #1e293b;
            --text: #e2e8f0;
            --text-muted: #94a3b8;
            --accent: #22d3ee;
        }
        * { margin: 0; padding: 0; box-sizing: border-box; }
        html { scroll-behavior: smooth; }
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: var(--bg-dark);
            color: var(--text);
            line-height: 1.8;
        }
        .container { max-width: 800px; margin: 0 auto; padding: 0 20px; }

        header {
            padding: 20px 0;
            border-bottom: 1px solid rgba(255,255,255,0.1);
            position: sticky;
            top: 0;
            background: rgba(15, 23, 42, 0.95);
            backdrop-filter: blur(10px);
            z-index: 100;
        }
        nav { display: flex; justify-content: space-between; align-items: center; max-width: 1200px; margin: 0 auto; padding: 0 20px; }
        .logo {
            font-size: 1.5rem;
            font-weight: 700;
            color: var(--primary);
            text-decoration: none;
            display: flex;
            align-items: center;
            gap: 10px;
        }
        .nav-links { display: flex; gap: 30px; list-style: none; }
        .nav-links a { color: var(--text-muted); text-decoration: none; font-weight: 500; }
        .nav-links a:hover { color: var(--accent); }

        /* Language Selector */
        .lang-selector {
            display: flex;
            align-items: center;
            gap: 5px;
            margin-left: 20px;
            background: var(--bg-card);
            border-radius: 8px;
            padding: 5px;
        }
        .lang-btn {
            background: transparent;
            border: none;
            color: var(--text-muted);
            padding: 5px 10px;
            border-radius: 5px;
            cursor: pointer;
            font-size: 0.85rem;
            font-weight: 500;
            transition: all 0.3s;
        }
        .lang-btn:hover { color: var(--text); }
        .lang-btn.active {
            background: var(--primary);
            color: white;
        }
        .nav-right {
            display: flex;
            align-items: center;
        }

        .hero {
            padding: 80px 0 60px;
            text-align: center;
            background: linear-gradient(135deg, rgba(99, 102, 241, 0.1) 0%, rgba(14, 165, 233, 0.05) 100%);
        }
        .hero h1 {
            font-size: 2.5rem;
            margin-bottom: 20px;
            background: linear-gradient(135deg, var(--primary), var(--accent));
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }
        .hero p { color: var(--text-muted); font-size: 1.2rem; }

        .content { padding: 60px 0; }
        .content h2 {
            font-size: 1.8rem;
            margin: 50px 0 25px;
            color: var(--accent);
            border-bottom: 1px solid rgba(255,255,255,0.1);
            padding-bottom: 10px;
        }
        .content h2:first-child { margin-top: 0; }
        .content p { margin-bottom: 20px; color: var(--text); }
        .content strong { color: var(--accent); }

        .analogy-box {
            background: var(--bg-card);
            border-left: 4px solid var(--primary);
            padding: 25px 30px;
            margin: 30px 0;
            border-radius: 0 12px 12px 0;
        }
        .analogy-box h3 {
            color: var(--primary);
            margin-bottom: 15px;
            font-size: 1.2rem;
        }

        .feature-section {
            background: var(--bg-card);
            padding: 40px;
            border-radius: 16px;
            margin: 40px 0;
        }
        .feature-section h3 {
            color: var(--text);
            font-size: 1.4rem;
            margin-bottom: 20px;
            display: flex;
            align-items: center;
            gap: 12px;
        }
        .feature-section p { color: var(--text-muted); }

        .back-link {
            display: inline-flex;
            align-items: center;
            gap: 8px;
            color: var(--primary);
            text-decoration: none;
            margin-top: 40px;
            font-weight: 500;
        }
        .back-link:hover { color: var(--accent); }

        footer {
            padding: 40px 0;
            border-top: 1px solid rgba(255,255,255,0.1);
            text-align: center;
        }
        footer p { color: var(--text-muted); font-size: 0.9rem; }
        footer a { color: var(--accent); text-decoration: none; }

        .diagram-container {
            background: var(--bg-card);
            border-radius: 16px;
            padding: 30px;
            margin: 30px 0;
            overflow-x: auto;
        }
        .diagram-container .mermaid {
            display: flex;
            justify-content: center;
        }
        .diagram-caption {
            text-align: center;
            color: var(--text-muted);
            font-size: 0.95rem;
            font-style: italic;
            margin-top: 20px;
        }

        @media (max-width: 768px) {
            .hero h1 { font-size: 2rem; }
            .nav-links { display: none; }
            .feature-section { padding: 25px; }
            .diagram-container { padding: 15px; }
        }
    </style>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
        mermaid.initialize({
            startOnLoad: true,
            theme: 'dark',
            themeVariables: {
                primaryColor: '#6366f1',
                primaryTextColor: '#e2e8f0',
                primaryBorderColor: '#6366f1',
                lineColor: '#94a3b8',
                secondaryColor: '#1e293b',
                tertiaryColor: '#0f172a',
                background: '#1e293b',
                mainBkg: '#1e293b',
                nodeBorder: '#6366f1',
                clusterBkg: '#1e293b',
                clusterBorder: '#6366f1',
                titleColor: '#e2e8f0',
                edgeLabelBackground: '#1e293b'
            },
            flowchart: {
                curve: 'basis',
                padding: 20
            }
        });
    </script>
</head>
<body>
    <header>
        <nav>
            <a href="/" class="logo"><span>üß†</span> R-JEPA</a>
            <div class="nav-right">
                <ul class="nav-links">
                    <li><a href="/" data-i18n="nav.home">Home</a></li>
                    <li><a href="#problem" data-i18n="nav.problem">The Problem</a></li>
                    <li><a href="#approach" data-i18n="nav.approach">Our Approach</a></li>
                    <li><a href="#modes" data-i18n="nav.modes">How It Helps</a></li>
                    <li><a href="https://github.com/Teleadmin-ai/rjepa">GitHub</a></li>
                </ul>
                <div class="lang-selector">
                    <button class="lang-btn" data-lang="en">EN</button>
                    <button class="lang-btn" data-lang="fr">FR</button>
                </div>
            </div>
        </nav>
    </header>

    <section class="hero">
        <div class="container">
            <h1 data-i18n="hero.title">Understanding R-JEPA</h1>
            <p data-i18n="hero.subtitle">What it does, why it matters, and how it works ‚Äî in plain language</p>
        </div>
    </section>

    <section class="content">
        <div class="container">

            <h2 id="problem" data-i18n="problem.title">The Problem We're Solving</h2>

            <p data-i18n="problem.p1">Large language models are remarkably capable, but they have a curious weakness: they don't really <em>think</em> about what they're saying. When a model solves a math problem or writes code, it's essentially predicting the next word based on patterns it learned during training. There's no internal voice checking if the reasoning makes sense.</p>

            <p data-i18n="problem.p2">This leads to a familiar frustration. The model confidently writes "Step 1... Step 2... Step 3..." ‚Äî and the final answer is wrong. Not because the model lacks knowledge, but because somewhere in the middle, a reasoning step went off track, and nothing caught it.</p>

            <p data-i18n="problem.p3">What if we could give the model a way to <strong>sense when its reasoning drifts</strong>? Not by adding more rules, but by teaching it what good reasoning <em>feels like</em> at a deeper level?</p>

            <h2 id="approach" data-i18n="approach.title">Our Approach: Learning the Shape of Good Reasoning</h2>

            <p data-i18n="approach.p1">R-JEPA takes a different approach from traditional methods. Instead of looking at the words a model produces, we look at its <strong>internal representations</strong> ‚Äî the hidden patterns of activation inside the neural network as it thinks through each step.</p>

            <p data-i18n="approach.p2">These internal states, which we call "latents," are like a fingerprint of what the model is actually computing at each moment. A correct reasoning step has a certain shape in this latent space. An incorrect one looks different.</p>

            <div class="analogy-box">
                <h3 data-i18n="approach.analogy.title">An Analogy</h3>
                <p data-i18n="approach.analogy.p1">Imagine watching someone solve a puzzle. You can't see their thoughts, but you notice their hand movements. Someone who knows what they're doing moves with a certain rhythm ‚Äî confident, directed, purposeful. Someone who's confused hesitates, backtracks, fumbles.</p>
                <p data-i18n="approach.analogy.p2">R-JEPA learns to recognize this rhythm, but in the space of neural activations. It learns what the "confident, directed, purposeful" pattern looks like for correct mathematical reasoning, logical deduction, or code writing.</p>
            </div>

            <p data-i18n="approach.p3">The key insight, borrowed from Yann LeCun's work on world models, is that we don't need to predict the actual words. We just need to predict what the <strong>internal state should be</strong> if the reasoning is proceeding correctly. When the actual state diverges from the expected state, something has gone wrong.</p>

            <h2 data-i18n="pipeline.title">How It Works ‚Äî The Pipeline</h2>

            <div class="diagram-container">
                <pre class="mermaid">
%%{init: {'theme': 'dark', 'themeVariables': { 'fontSize': '14px' }}}%%
flowchart TB
    subgraph INPUT["<b>üì• INPUT</b>"]
        direction TB
        P["üß© <b>Problem</b><br/><i>Solve: 2x + 5 = 13</i>"]
    end

    subgraph LLM["<b>ü§ñ LANGUAGE MODEL</b> (Qwen3-8B)"]
        direction TB
        G["‚öôÔ∏è Generate Reasoning"]
        subgraph STEPS["Reasoning Chain"]
            direction LR
            S1["<b>Step 1</b><br/>Subtract 5"]
            S2["<b>Step 2</b><br/>2x = 8"]
            S3["<b>Step 3</b><br/>Divide by 2"]
            S4["<b>Step 4</b><br/>x = 4"]
        end
    end

    subgraph EXTRACT["<b>üî¨ LATENT EXTRACTION</b> (Layer -2)"]
        direction LR
        H1["<b>h‚ÇÅ</b><br/>4096d"]
        H2["<b>h‚ÇÇ</b><br/>4096d"]
        H3["<b>h‚ÇÉ</b><br/>4096d"]
        H4["<b>h‚ÇÑ</b><br/>4096d"]
    end

    subgraph RJEPA["<b>‚ö° R-JEPA WORLD MODEL</b>"]
        direction TB
        subgraph ONLINE["<span style='color:#22c55e'><b>TRAINABLE</b></span>"]
            direction LR
            CE["üü¢ <b>Context Encoder</b><br/>6 layers, 2048d"]
            PR["üîµ <b>Predictor</b><br/>4 layers"]
        end
        subgraph FROZEN["<span style='color:#f59e0b'><b>EMA FROZEN</b></span>"]
            TE["üü° <b>Target Encoder</b><br/>œÑ = 0.996"]
        end
    end

    subgraph COMPARE["<b>üìä COMPARISON</b>"]
        direction TB
        ZPRED["·∫ë‚ÇÉ<br/><i>predicted</i>"]
        ZTARGET["z‚ÇÉ<br/><i>actual</i>"]
        LOSS["üìâ <b>L1 Loss</b><br/>+ variance reg"]
    end

    subgraph OUTPUT["<b>üì§ OUTPUT</b>"]
        direction TB
        SCORE["‚úÖ <b>Coherence Score</b><br/><i>0.92 - High confidence</i>"]
        GUIDE["üéØ <b>Guidance Signal</b><br/><i>For NUDGE mode</i>"]
    end

    P --> G
    G --> STEPS
    S1 --> H1
    S2 --> H2
    S3 --> H3
    S4 --> H4

    H1 & H2 --> CE
    CE --> PR
    PR --> ZPRED

    H3 --> TE
    TE --> ZTARGET

    ZPRED --> LOSS
    ZTARGET --> LOSS

    LOSS --> SCORE
    LOSS --> GUIDE

    style INPUT fill:#0f172a,stroke:#6366f1,stroke-width:2px,color:#e2e8f0
    style LLM fill:#0f172a,stroke:#0ea5e9,stroke-width:2px,color:#e2e8f0
    style STEPS fill:#1e293b,stroke:#0ea5e9,stroke-width:1px,color:#e2e8f0
    style EXTRACT fill:#0f172a,stroke:#22d3ee,stroke-width:2px,color:#e2e8f0
    style RJEPA fill:#0f172a,stroke:#6366f1,stroke-width:3px,color:#e2e8f0
    style ONLINE fill:#134e4a,stroke:#22c55e,stroke-width:2px,color:#e2e8f0
    style FROZEN fill:#422006,stroke:#f59e0b,stroke-width:2px,color:#e2e8f0
    style COMPARE fill:#0f172a,stroke:#a78bfa,stroke-width:2px,color:#e2e8f0
    style OUTPUT fill:#0f172a,stroke:#22c55e,stroke-width:2px,color:#e2e8f0
                </pre>
            </div>

            <p class="diagram-caption" data-i18n="pipeline.caption">
                <b>The R-JEPA Pipeline:</b> A problem enters the LLM which generates step-by-step reasoning.
                Each step's hidden state (4096-dim vector from layer -2) is extracted.
                R-JEPA's Context Encoder + Predictor learn to predict the next latent (·∫ë‚ÇÉ) from visible context (h‚ÇÅ, h‚ÇÇ).
                The Target Encoder (EMA) provides the ground truth (z‚ÇÉ).
                Low L1 loss = coherent reasoning. High loss = potential error detected.
            </p>

            <h2 id="modes" data-i18n="modes.title">Three Ways R-JEPA Helps</h2>

            <div class="feature-section">
                <h3 data-i18n="modes.rerank.title">üéØ RERANK ‚Äî Picking the Best Answer</h3>
                <p data-i18n="modes.rerank.p1">The simplest use case. We ask the language model to generate several different solutions to the same problem. Then R-JEPA scores each one based on how "coherent" the reasoning looks in latent space.</p>
                <p data-i18n="modes.rerank.p2">A solution where each step flows naturally from the previous one will score better than a solution with logical jumps or inconsistencies ‚Äî even if both arrive at an answer. This doesn't guarantee correctness, but it significantly improves the odds of picking a good solution.</p>
            </div>

            <div class="feature-section">
                <h3 data-i18n="modes.nudge.title">üîÑ NUDGE ‚Äî Gentle Course Correction</h3>
                <p data-i18n="modes.nudge.p1">This is more subtle. Instead of just scoring complete solutions, R-JEPA can influence the model <em>while it's generating</em>. At each step, it predicts what a good next state should look like, then gently biases the model's word choices toward that target.</p>
                <p data-i18n="modes.nudge.p2">Think of it like a GPS that doesn't just tell you when you've arrived at the wrong destination ‚Äî it notices when you're about to take a wrong turn and suggests a correction before you commit to it.</p>
                <p data-i18n="modes.nudge.p3">The bias is gentle (adjustable from subtle to strong), so the model can still follow its intuition while being guided toward more coherent reasoning paths.</p>
            </div>

            <div class="feature-section">
                <h3 data-i18n="modes.plan.title">üìù PLAN ‚Äî Filling in the Gaps</h3>
                <p data-i18n="modes.plan.p1">Sometimes a model skips steps. It might jump from "we need to solve for x" to "therefore x = 4" without showing the work. R-JEPA can detect these gaps by noticing that the latent space jumped unexpectedly.</p>
                <p data-i18n="modes.plan.p2">More importantly, it can predict what the missing steps <em>should</em> look like, and translate those predictions back into text. This helps produce more complete, verifiable reasoning chains.</p>
            </div>

            <h2 data-i18n="models.title">Working with Different Models</h2>

            <p data-i18n="models.p1">One practical concern: does this only work with one specific language model? Not quite. The latent space of different models in the same family (like Qwen 8B and Qwen 32B) have similar structures. We can train R-JEPA on a smaller model and then adapt it to work with larger ones through a brief calibration process.</p>

            <p data-i18n="models.p2">This means you can develop and test on accessible hardware, then deploy with more powerful models when needed, without starting from scratch.</p>

            <h2 data-i18n="limitations.title">What This Isn't</h2>

            <p data-i18n="limitations.p1">R-JEPA is not a magic solution. It can't make a model understand concepts it never learned. It can't guarantee correct answers. It's not a replacement for careful prompt engineering or domain-specific fine-tuning.</p>

            <p data-i18n="limitations.p2">What it offers is a <strong>new lens</strong> on the reasoning process ‚Äî a way to evaluate and guide model outputs that goes beyond just looking at the words. Think of it as adding a layer of introspection to systems that otherwise operate on pure pattern matching.</p>

            <h2 data-i18n="vision.title">The Bigger Picture</h2>

            <p data-i18n="vision.p1">This project embodies a fundamental conviction: AI systems need an internal model of what they're doing, not just pattern matching on outputs. The V-JEPA approach from Meta AI demonstrated this was possible for video ‚Äî predicting what should happen next in a scene by understanding the underlying dynamics. R-JEPA applies this same principle to reasoning in text.</p>

            <p data-i18n="vision.p2">Our goal is ambitious: to build AI systems that truly understand the structure of valid reasoning, that can detect when thinking goes astray, and that can guide themselves back toward coherent solutions. This is a step toward machines that don't just generate plausible text, but that genuinely reason ‚Äî systems more reliable, more interpretable, and more aligned with how we'd want a thoughtful agent to behave.</p>

            <a href="/" class="back-link">
                <svg width="20" height="20" fill="none" stroke="currentColor" stroke-width="2" viewBox="0 0 24 24"><path d="M19 12H5M12 19l-7-7 7-7"/></svg>
                <span data-i18n="backToHome">Back to Home</span>
            </a>
        </div>
    </section>

    <footer>
        <p data-i18n="footer.copyright">&copy; 2025 <a href="https://github.com/Teleadmin-ai">Teleadmin</a>. Created by Romain Provencal.</p>
    </footer>

    <script>
        // Translations for About page
        const translations = {
            en: {
                // Navigation
                "nav.home": "Home",
                "nav.problem": "The Problem",
                "nav.approach": "Our Approach",
                "nav.modes": "How It Helps",

                // Hero
                "hero.title": "Understanding R-JEPA",
                "hero.subtitle": "What it does, why it matters, and how it works ‚Äî in plain language",

                // Problem Section
                "problem.title": "The Problem We're Solving",
                "problem.p1": "Large language models are remarkably capable, but they have a curious weakness: they don't really <em>think</em> about what they're saying. When a model solves a math problem or writes code, it's essentially predicting the next word based on patterns it learned during training. There's no internal voice checking if the reasoning makes sense.",
                "problem.p2": "This leads to a familiar frustration. The model confidently writes \"Step 1... Step 2... Step 3...\" ‚Äî and the final answer is wrong. Not because the model lacks knowledge, but because somewhere in the middle, a reasoning step went off track, and nothing caught it.",
                "problem.p3": "What if we could give the model a way to <strong>sense when its reasoning drifts</strong>? Not by adding more rules, but by teaching it what good reasoning <em>feels like</em> at a deeper level?",

                // Approach Section
                "approach.title": "Our Approach: Learning the Shape of Good Reasoning",
                "approach.p1": "R-JEPA takes a different approach from traditional methods. Instead of looking at the words a model produces, we look at its <strong>internal representations</strong> ‚Äî the hidden patterns of activation inside the neural network as it thinks through each step.",
                "approach.p2": "These internal states, which we call \"latents,\" are like a fingerprint of what the model is actually computing at each moment. A correct reasoning step has a certain shape in this latent space. An incorrect one looks different.",
                "approach.analogy.title": "An Analogy",
                "approach.analogy.p1": "Imagine watching someone solve a puzzle. You can't see their thoughts, but you notice their hand movements. Someone who knows what they're doing moves with a certain rhythm ‚Äî confident, directed, purposeful. Someone who's confused hesitates, backtracks, fumbles.",
                "approach.analogy.p2": "R-JEPA learns to recognize this rhythm, but in the space of neural activations. It learns what the \"confident, directed, purposeful\" pattern looks like for correct mathematical reasoning, logical deduction, or code writing.",
                "approach.p3": "The key insight, borrowed from Yann LeCun's work on world models, is that we don't need to predict the actual words. We just need to predict what the <strong>internal state should be</strong> if the reasoning is proceeding correctly. When the actual state diverges from the expected state, something has gone wrong.",

                // Pipeline Section
                "pipeline.title": "How It Works ‚Äî The Pipeline",
                "pipeline.caption": "<b>The R-JEPA Pipeline:</b> A problem enters the LLM which generates step-by-step reasoning. Each step's hidden state (4096-dim vector from layer -2) is extracted. R-JEPA's Context Encoder + Predictor learn to predict the next latent (·∫ë‚ÇÉ) from visible context (h‚ÇÅ, h‚ÇÇ). The Target Encoder (EMA) provides the ground truth (z‚ÇÉ). Low L1 loss = coherent reasoning. High loss = potential error detected.",

                // Modes Section
                "modes.title": "Three Ways R-JEPA Helps",
                "modes.rerank.title": "üéØ RERANK ‚Äî Picking the Best Answer",
                "modes.rerank.p1": "The simplest use case. We ask the language model to generate several different solutions to the same problem. Then R-JEPA scores each one based on how \"coherent\" the reasoning looks in latent space.",
                "modes.rerank.p2": "A solution where each step flows naturally from the previous one will score better than a solution with logical jumps or inconsistencies ‚Äî even if both arrive at an answer. This doesn't guarantee correctness, but it significantly improves the odds of picking a good solution.",
                "modes.nudge.title": "üîÑ NUDGE ‚Äî Gentle Course Correction",
                "modes.nudge.p1": "This is more subtle. Instead of just scoring complete solutions, R-JEPA can influence the model <em>while it's generating</em>. At each step, it predicts what a good next state should look like, then gently biases the model's word choices toward that target.",
                "modes.nudge.p2": "Think of it like a GPS that doesn't just tell you when you've arrived at the wrong destination ‚Äî it notices when you're about to take a wrong turn and suggests a correction before you commit to it.",
                "modes.nudge.p3": "The bias is gentle (adjustable from subtle to strong), so the model can still follow its intuition while being guided toward more coherent reasoning paths.",
                "modes.plan.title": "üìù PLAN ‚Äî Filling in the Gaps",
                "modes.plan.p1": "Sometimes a model skips steps. It might jump from \"we need to solve for x\" to \"therefore x = 4\" without showing the work. R-JEPA can detect these gaps by noticing that the latent space jumped unexpectedly.",
                "modes.plan.p2": "More importantly, it can predict what the missing steps <em>should</em> look like, and translate those predictions back into text. This helps produce more complete, verifiable reasoning chains.",

                // Models Section
                "models.title": "Working with Different Models",
                "models.p1": "One practical concern: does this only work with one specific language model? Not quite. The latent space of different models in the same family (like Qwen 8B and Qwen 32B) have similar structures. We can train R-JEPA on a smaller model and then adapt it to work with larger ones through a brief calibration process.",
                "models.p2": "This means you can develop and test on accessible hardware, then deploy with more powerful models when needed, without starting from scratch.",

                // Limitations Section
                "limitations.title": "What This Isn't",
                "limitations.p1": "R-JEPA is not a magic solution. It can't make a model understand concepts it never learned. It can't guarantee correct answers. It's not a replacement for careful prompt engineering or domain-specific fine-tuning.",
                "limitations.p2": "What it offers is a <strong>new lens</strong> on the reasoning process ‚Äî a way to evaluate and guide model outputs that goes beyond just looking at the words. Think of it as adding a layer of introspection to systems that otherwise operate on pure pattern matching.",

                // Vision Section
                "vision.title": "The Bigger Picture",
                "vision.p1": "This project embodies a fundamental conviction: AI systems need an internal model of what they're doing, not just pattern matching on outputs. The V-JEPA approach from Meta AI demonstrated this was possible for video ‚Äî predicting what should happen next in a scene by understanding the underlying dynamics. R-JEPA applies this same principle to reasoning in text.",
                "vision.p2": "Our goal is ambitious: to build AI systems that truly understand the structure of valid reasoning, that can detect when thinking goes astray, and that can guide themselves back toward coherent solutions. This is a step toward machines that don't just generate plausible text, but that genuinely reason ‚Äî systems more reliable, more interpretable, and more aligned with how we'd want a thoughtful agent to behave.",

                // Footer
                "backToHome": "Back to Home",
                "footer.copyright": "&copy; 2025 <a href=\"https://github.com/Teleadmin-ai\">Teleadmin</a>. Created by Romain Provencal."
            },
            fr: {
                // Navigation
                "nav.home": "Accueil",
                "nav.problem": "Le Probl√®me",
                "nav.approach": "Notre Approche",
                "nav.modes": "Comment √ßa aide",

                // Hero
                "hero.title": "Comprendre R-JEPA",
                "hero.subtitle": "Ce qu'il fait, pourquoi c'est important, et comment √ßa marche ‚Äî en langage simple",

                // Problem Section
                "problem.title": "Le Probl√®me Que Nous R√©solvons",
                "problem.p1": "Les grands mod√®les de langage sont remarquablement capables, mais ils ont une faiblesse curieuse : ils ne <em>r√©fl√©chissent</em> pas vraiment √† ce qu'ils disent. Quand un mod√®le r√©sout un probl√®me de maths ou √©crit du code, il pr√©dit essentiellement le prochain mot bas√© sur des patterns appris pendant l'entra√Ænement. Il n'y a pas de voix interne qui v√©rifie si le raisonnement a du sens.",
                "problem.p2": "Cela conduit √† une frustration famili√®re. Le mod√®le √©crit avec confiance ¬´ √âtape 1... √âtape 2... √âtape 3... ¬ª ‚Äî et la r√©ponse finale est fausse. Non pas parce que le mod√®le manque de connaissances, mais parce que quelque part au milieu, une √©tape de raisonnement a d√©vi√©, et rien ne l'a d√©tect√©.",
                "problem.p3": "Et si nous pouvions donner au mod√®le un moyen de <strong>sentir quand son raisonnement d√©rive</strong> ? Non pas en ajoutant plus de r√®gles, mais en lui apprenant ce que ressemble un bon raisonnement √† un niveau plus profond.",

                // Approach Section
                "approach.title": "Notre Approche : Apprendre la Forme du Bon Raisonnement",
                "approach.p1": "R-JEPA adopte une approche diff√©rente des m√©thodes traditionnelles. Au lieu de regarder les mots qu'un mod√®le produit, nous regardons ses <strong>repr√©sentations internes</strong> ‚Äî les patterns cach√©s d'activation √† l'int√©rieur du r√©seau neuronal pendant qu'il r√©fl√©chit √† chaque √©tape.",
                "approach.p2": "Ces √©tats internes, que nous appelons ¬´ latents ¬ª, sont comme une empreinte digitale de ce que le mod√®le calcule r√©ellement √† chaque instant. Une √©tape de raisonnement correcte a une certaine forme dans cet espace latent. Une incorrecte est diff√©rente.",
                "approach.analogy.title": "Une Analogie",
                "approach.analogy.p1": "Imaginez regarder quelqu'un r√©soudre un puzzle. Vous ne pouvez pas voir ses pens√©es, mais vous remarquez ses mouvements de main. Quelqu'un qui sait ce qu'il fait bouge avec un certain rythme ‚Äî confiant, dirig√©, d√©lib√©r√©. Quelqu'un qui est confus h√©site, revient en arri√®re, t√¢tonne.",
                "approach.analogy.p2": "R-JEPA apprend √† reconna√Ætre ce rythme, mais dans l'espace des activations neuronales. Il apprend √† quoi ressemble le pattern ¬´ confiant, dirig√©, d√©lib√©r√© ¬ª pour un raisonnement math√©matique correct, une d√©duction logique, ou l'√©criture de code.",
                "approach.p3": "L'intuition cl√©, emprunt√©e aux travaux de Yann LeCun sur les world models, est que nous n'avons pas besoin de pr√©dire les mots r√©els. Nous devons juste pr√©dire ce que <strong>l'√©tat interne devrait √™tre</strong> si le raisonnement se d√©roule correctement. Quand l'√©tat r√©el diverge de l'√©tat attendu, quelque chose s'est mal pass√©.",

                // Pipeline Section
                "pipeline.title": "Comment √áa Marche ‚Äî Le Pipeline",
                "pipeline.caption": "<b>Le Pipeline R-JEPA :</b> Un probl√®me entre dans le LLM qui g√©n√®re un raisonnement √©tape par √©tape. L'√©tat cach√© de chaque √©tape (vecteur 4096-dim de la couche -2) est extrait. L'Encoder de Contexte + Pr√©dicteur de R-JEPA apprennent √† pr√©dire le prochain latent (·∫ë‚ÇÉ) √† partir du contexte visible (h‚ÇÅ, h‚ÇÇ). L'Encoder Cible (EMA) fournit la v√©rit√© terrain (z‚ÇÉ). Faible perte L1 = raisonnement coh√©rent. Perte √©lev√©e = erreur potentielle d√©tect√©e.",

                // Modes Section
                "modes.title": "Trois Fa√ßons Dont R-JEPA Aide",
                "modes.rerank.title": "üéØ RERANK ‚Äî Choisir la Meilleure R√©ponse",
                "modes.rerank.p1": "Le cas d'utilisation le plus simple. Nous demandons au mod√®le de langage de g√©n√©rer plusieurs solutions diff√©rentes au m√™me probl√®me. Puis R-JEPA note chacune selon √† quel point le raisonnement semble ¬´ coh√©rent ¬ª dans l'espace latent.",
                "modes.rerank.p2": "Une solution o√π chaque √©tape d√©coule naturellement de la pr√©c√©dente aura un meilleur score qu'une solution avec des sauts logiques ou des incoh√©rences ‚Äî m√™me si les deux arrivent √† une r√©ponse. Cela ne garantit pas la correction, mais am√©liore significativement les chances de choisir une bonne solution.",
                "modes.nudge.title": "üîÑ NUDGE ‚Äî Correction de Trajectoire Douce",
                "modes.nudge.p1": "C'est plus subtil. Au lieu de juste noter des solutions compl√®tes, R-JEPA peut influencer le mod√®le <em>pendant qu'il g√©n√®re</em>. √Ä chaque √©tape, il pr√©dit √† quoi devrait ressembler le prochain bon √©tat, puis biaise doucement les choix de mots du mod√®le vers cette cible.",
                "modes.nudge.p2": "Pensez-y comme un GPS qui ne vous dit pas juste quand vous √™tes arriv√© √† la mauvaise destination ‚Äî il remarque quand vous √™tes sur le point de prendre un mauvais virage et sugg√®re une correction avant que vous ne vous y engagiez.",
                "modes.nudge.p3": "Le biais est doux (ajustable de subtil √† fort), donc le mod√®le peut toujours suivre son intuition tout en √©tant guid√© vers des chemins de raisonnement plus coh√©rents.",
                "modes.plan.title": "üìù PLAN ‚Äî Combler les Lacunes",
                "modes.plan.p1": "Parfois un mod√®le saute des √©tapes. Il peut passer de ¬´ nous devons r√©soudre x ¬ª √† ¬´ donc x = 4 ¬ª sans montrer le travail. R-JEPA peut d√©tecter ces lacunes en remarquant que l'espace latent a saut√© de mani√®re inattendue.",
                "modes.plan.p2": "Plus important encore, il peut pr√©dire √† quoi les √©tapes manquantes <em>devraient</em> ressembler, et traduire ces pr√©dictions en texte. Cela aide √† produire des cha√Ænes de raisonnement plus compl√®tes et v√©rifiables.",

                // Models Section
                "models.title": "Travailler avec Diff√©rents Mod√®les",
                "models.p1": "Une pr√©occupation pratique : est-ce que cela fonctionne seulement avec un mod√®le de langage sp√©cifique ? Pas tout √† fait. L'espace latent de diff√©rents mod√®les de la m√™me famille (comme Qwen 8B et Qwen 32B) ont des structures similaires. Nous pouvons entra√Æner R-JEPA sur un mod√®le plus petit puis l'adapter pour fonctionner avec des mod√®les plus grands via un bref processus de calibration.",
                "models.p2": "Cela signifie que vous pouvez d√©velopper et tester sur du mat√©riel accessible, puis d√©ployer avec des mod√®les plus puissants quand n√©cessaire, sans repartir de z√©ro.",

                // Limitations Section
                "limitations.title": "Ce Que Ce N'Est Pas",
                "limitations.p1": "R-JEPA n'est pas une solution magique. Il ne peut pas faire comprendre √† un mod√®le des concepts qu'il n'a jamais appris. Il ne peut pas garantir des r√©ponses correctes. Ce n'est pas un remplacement pour un prompt engineering soign√© ou un fine-tuning sp√©cifique au domaine.",
                "limitations.p2": "Ce qu'il offre est une <strong>nouvelle perspective</strong> sur le processus de raisonnement ‚Äî une fa√ßon d'√©valuer et guider les sorties du mod√®le qui va au-del√† de simplement regarder les mots. Pensez-y comme ajouter une couche d'introspection √† des syst√®mes qui autrement op√®rent sur du simple pattern matching.",

                // Vision Section
                "vision.title": "La Vision Globale",
                "vision.p1": "Ce projet incarne une conviction fondamentale : les syst√®mes d'IA ont besoin d'un mod√®le interne de ce qu'ils font, pas juste du pattern matching sur les sorties. L'approche V-JEPA de Meta AI a d√©montr√© que c'√©tait possible pour la vid√©o ‚Äî pr√©dire ce qui devrait se passer ensuite dans une sc√®ne en comprenant la dynamique sous-jacente. R-JEPA applique ce m√™me principe au raisonnement textuel.",
                "vision.p2": "Notre objectif est ambitieux : construire des syst√®mes d'IA qui comprennent vraiment la structure du raisonnement valide, qui peuvent d√©tecter quand la pens√©e d√©vie, et qui peuvent se guider eux-m√™mes vers des solutions coh√©rentes. C'est un pas vers des machines qui ne font pas que g√©n√©rer du texte plausible, mais qui raisonnent v√©ritablement ‚Äî des syst√®mes plus fiables, plus interpr√©tables, et plus align√©s avec comment nous voudrions qu'un agent r√©fl√©chi se comporte.",

                // Footer
                "backToHome": "Retour √† l'Accueil",
                "footer.copyright": "&copy; 2025 <a href=\"https://github.com/Teleadmin-ai\">Teleadmin</a>. Cr√©√© par Romain Provencal."
            }
        };

        // Apply translations
        function setLanguage(lang) {
            document.querySelectorAll('[data-i18n]').forEach(el => {
                const key = el.getAttribute('data-i18n');
                if (translations[lang] && translations[lang][key]) {
                    el.innerHTML = translations[lang][key];
                }
            });

            // Update active button
            document.querySelectorAll('.lang-btn').forEach(btn => {
                btn.classList.toggle('active', btn.dataset.lang === lang);
            });

            // Save preference
            localStorage.setItem('rjepa-lang', lang);

            // Update HTML lang attribute
            document.documentElement.lang = lang;
        }

        // Initialize language
        document.addEventListener('DOMContentLoaded', () => {
            // Get saved language or detect from browser
            const savedLang = localStorage.getItem('rjepa-lang');
            const browserLang = navigator.language.startsWith('fr') ? 'fr' : 'en';
            const initialLang = savedLang || browserLang;

            setLanguage(initialLang);

            // Add click handlers
            document.querySelectorAll('.lang-btn').forEach(btn => {
                btn.addEventListener('click', () => setLanguage(btn.dataset.lang));
            });
        });
    </script>
</body>
</html>
