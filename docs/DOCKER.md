# ğŸ³ Docker Compose â€” Architecture ComplÃ¨te

Documentation dÃ©taillÃ©e de l'orchestration Docker pour R-JEPA.

## Sommaire

1. [Vue d'ensemble des services](#vue-densemble-des-services)
2. [docker-compose.yml](#docker-composeyml)
3. [docker-compose.dev.yml](#docker-composedevyml)
4. [Usage](#usage)
5. [AccÃ¨s aux services](#accÃ¨s-aux-services)

---

## Vue d'ensemble des services

**OBJECTIF** : Tous les services dans des conteneurs Docker, orchestrÃ©s par docker-compose.
Windows + NVIDIA GPU â†’ utilise nvidia-docker runtime.

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SERVICES                                                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1. student-llm       : Serveur vLLM avec Qwen3-8B + extraction latents     â”‚
â”‚ 2. rjepa-service     : API R-JEPA (score, predict, correct)                â”‚
â”‚ 3. teacher-orch      : Teacher orchestrator (gÃ©nÃ©ra + valida)              â”‚
â”‚ 4. data-pipeline     : Prefect server + workers pour jobs                  â”‚
â”‚ 5. ui-backend        : Gateway FastAPI (WebSocket, auth)                   â”‚
â”‚ 6. ui-frontend       : Next.js app (dev ou build prod)                     â”‚
â”‚ 7. duckdb            : Service DuckDB (queries sur parquet)                â”‚
â”‚ 8. prefect-server    : Prefect UI (monitoring jobs)                        â”‚
â”‚ 9. wandb-local       : (Optionnel) Instance W&B locale si offline          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

**RÃ‰SEAU** : Tous les services sur rÃ©seau Docker "rjepa-network" (bridge).
**VOLUMES** : PartagÃ©s entre services pour data/, logs/, checkpoints/.

---

## docker-compose.yml

```yaml
version: '3.8'

services:
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # 1. STUDENT LLM (vLLM server avec Qwen3-8B)
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  student-llm:
    build:
      context: .
      dockerfile: docker/student-llm.Dockerfile
    image: rjepa/student-llm:latest
    container_name: rjepa-student-llm
    restart: unless-stopped

    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

    environment:
      - CUDA_VISIBLE_DEVICES=0
      - MODEL_NAME=Qwen/Qwen3-8B-Instruct
      - QUANTIZATION=awq-4bit
      - MAX_MODEL_LEN=4096
      - GPU_MEMORY_UTILIZATION=0.85
      - LAYER_TO_EXTRACT=-2          # Avant-derniÃ¨re couche

    ports:
      - "8000:8000"                   # vLLM OpenAI-compatible API
      - "8001:8001"                   # Latent extraction API (custom)

    volumes:
      - ./data:/app/data
      - ./logs/student-llm:/app/logs
      - huggingface_cache:/root/.cache/huggingface

    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

    networks:
      - rjepa-network

  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # 2. R-JEPA SERVICE (inference API)
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  rjepa-service:
    build:
      context: .
      dockerfile: docker/rjepa.Dockerfile
    image: rjepa/rjepa-service:latest
    container_name: rjepa-service
    restart: unless-stopped

    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

    environment:
      - CUDA_VISIBLE_DEVICES=0
      - RJEPA_CHECKPOINT=/app/data/checkpoints/rjepa-qwen3-8b/latest.pth
      - RJEPA_CONFIG=/app/configs/rjepa/base.yaml

    ports:
      - "8100:8100"                   # R-JEPA API

    volumes:
      - ./data:/app/data
      - ./configs:/app/configs
      - ./logs/rjepa:/app/logs

    depends_on:
      - student-llm

    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8100/health"]
      interval: 30s
      timeout: 10s
      retries: 3

    networks:
      - rjepa-network

  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # 3. TEACHER ORCHESTRATOR
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  teacher-orch:
    build:
      context: .
      dockerfile: docker/teacher-orch.Dockerfile
    image: rjepa/teacher-orch:latest
    container_name: rjepa-teacher-orch
    restart: unless-stopped

    environment:
      - TEACHER_CLAUDE_BASE_URL=${TEACHER_CLAUDE_BASE_URL}
      - TEACHER_CLAUDE_API_KEY=${TEACHER_CLAUDE_API_KEY}
      - TEACHER_CLAUDE_MODEL=${TEACHER_CLAUDE_MODEL}
      - TEACHER_GPT_BASE_URL=${TEACHER_GPT_BASE_URL}
      - TEACHER_GPT_API_KEY=${TEACHER_GPT_API_KEY}
      - TEACHER_GPT_MODEL=${TEACHER_GPT_MODEL}
      - TEACHER_MAX_BUDGET_PER_JOB=${TEACHER_MAX_BUDGET_PER_JOB:-50.0}

    ports:
      - "8200:8200"                   # Teacher API

    volumes:
      - ./data:/app/data
      - ./configs/teacher:/app/configs
      - ./logs/teacher:/app/logs

    networks:
      - rjepa-network

  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # 4. DATA PIPELINE (Prefect worker)
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  data-pipeline:
    build:
      context: .
      dockerfile: docker/data-pipeline.Dockerfile
    image: rjepa/data-pipeline:latest
    container_name: rjepa-data-pipeline
    restart: unless-stopped

    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

    environment:
      - PREFECT_API_URL=http://prefect-server:4200/api
      - CUDA_VISIBLE_DEVICES=0

    volumes:
      - ./data:/app/data
      - ./configs:/app/configs
      - ./logs/pipeline:/app/logs

    depends_on:
      - prefect-server
      - student-llm
      - teacher-orch

    command: prefect agent start -q default

    networks:
      - rjepa-network

  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # 5. PREFECT SERVER (orchestration UI)
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  prefect-server:
    image: prefecthq/prefect:2-python3.11
    container_name: rjepa-prefect-server
    restart: unless-stopped

    ports:
      - "4200:4200"                   # Prefect UI

    environment:
      - PREFECT_SERVER_API_HOST=0.0.0.0
      - PREFECT_API_DATABASE_CONNECTION_URL=sqlite:///prefect.db

    volumes:
      - prefect_data:/root/.prefect

    command: prefect server start --host 0.0.0.0

    networks:
      - rjepa-network

  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # 6. UI BACKEND (Gateway FastAPI + WebSocket)
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  ui-backend:
    build:
      context: .
      dockerfile: docker/ui-backend.Dockerfile
    image: rjepa/ui-backend:latest
    container_name: rjepa-ui-backend
    restart: unless-stopped

    environment:
      - STUDENT_LLM_URL=http://student-llm:8000
      - RJEPA_SERVICE_URL=http://rjepa-service:8100
      - PREFECT_API_URL=http://prefect-server:4200/api

    ports:
      - "8300:8300"                   # UI backend API

    volumes:
      - ./logs/interactions:/app/logs/interactions

    depends_on:
      - student-llm
      - rjepa-service
      - prefect-server

    networks:
      - rjepa-network

  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # 7. UI FRONTEND (Next.js)
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  ui-frontend:
    build:
      context: ./ui/web
      dockerfile: ../../docker/ui-frontend.Dockerfile
    image: rjepa/ui-frontend:latest
    container_name: rjepa-ui-frontend
    restart: unless-stopped

    environment:
      - NEXT_PUBLIC_API_URL=http://localhost:8300

    ports:
      - "3000:3000"                   # Next.js app

    depends_on:
      - ui-backend

    networks:
      - rjepa-network

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# VOLUMES PARTAGÃ‰S
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
volumes:
  huggingface_cache:                # Cache modÃ¨les HF (persistant)
  prefect_data:                     # DB Prefect

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# RÃ‰SEAU
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
networks:
  rjepa-network:
    driver: bridge
```

---

## docker-compose.dev.yml

Override pour dÃ©veloppement local avec hot reload.

**Utiliser:** `docker-compose -f docker-compose.yml -f docker-compose.dev.yml up`

```yaml
version: '3.8'

services:
  student-llm:
    environment:
      - LOG_LEVEL=DEBUG
    volumes:
      - ./rjepa:/app/rjepa:ro      # Mount code en lecture seule pour hot reload

  rjepa-service:
    environment:
      - LOG_LEVEL=DEBUG
    volumes:
      - ./rjepa:/app/rjepa:ro

  ui-frontend:
    command: npm run dev             # Mode dev Next.js (hot reload)
    volumes:
      - ./ui/web:/app:delegated      # Mount UI code pour hot reload
```

---

## Usage

```bash
# Build toutes les images
make docker-build
# ou: docker-compose build

# Lancer tous les services (prod)
make docker-up
# ou: docker-compose up -d

# Lancer en mode dev (avec hot reload)
docker-compose -f docker-compose.yml -f docker-compose.dev.yml up

# Voir les logs
make docker-logs
# ou: docker-compose logs -f

# ArrÃªter
make docker-down
# ou: docker-compose down

# Rebuild un seul service
docker-compose build student-llm
docker-compose up -d student-llm
```

---

## AccÃ¨s aux services

| Service | URL | Description |
|---------|-----|-------------|
| Chat UI | http://localhost:3000 | Interface utilisateur Next.js |
| Prefect UI | http://localhost:4200 | Monitoring des jobs |
| Student LLM API | http://localhost:8000 | API vLLM OpenAI-compatible |
| R-JEPA API | http://localhost:8100 | API inference R-JEPA |
| Teacher API | http://localhost:8200 | API Teacher orchestrator |
| UI Backend | http://localhost:8300 | Gateway FastAPI |
